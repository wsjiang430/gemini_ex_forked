Prompt: Summarize the business model from the following text. Answer with a continuous text and with fivehundredtwelve tokens at max. Set your focus on sources of revenue , the intended customer base , products , distribution channels  and details of financing. Use only information from the following the text:

ITEM 1. BUSINESS
Overview
Ambarella is a leading developer of low-power system-on-a-chip, or SoC, semiconductors and software for edge artificial intelligence, or AI, applications. Our technologies make electronic systems smarter, enabling features such as person detection, object classification, and analytics, in addition to performing complex data analysis in real time, delivering high quality imagery, and preserving vital system resources such as power and network bandwidth. We specialize in the development of deployable, scalable designs for intelligent electronic systems that utilize high-bandwidth sensors offering a proven path to mass production.
 Incorporated in 2004, we have primarily served human-viewing applications with video and image processors for enterprise, public infrastructure and home applications, such as internet protocol, or IP, security cameras, sports cameras, wearables, aerial drones, and aftermarket automotive video recorders. We are now leveraging our human-viewing heritage to pursue the machine sensing market. Our recent development efforts have focused on creating advanced AI technology that enables edge devices to visually perceive the environment and make decisions based on the data collected from cameras and other types of sensors, such as 4D radar. This category of AI technology is known as computer vision, or CV, and our CV SoCs integrate our state-of-the-art video processor technology together with our recently developed deep learning neural network processing technology, which we refer to as CVflow®. The CVflow-architecture supports a variety of computer vision algorithms, including, object detection, classification and tracking, semantic and instance segmentation, image processing, stereo object detection, terrain mapping, and face recognition. In addition, CVflow can process other sensor modalities, including lidar, radar, time of flight, thermal and near infrared (NIR), and allows customers to differentiate their products by porting their own or third party neural networks and/or classical computer vision algorithms to our CVflow-based SoCs. Our CV technology is creating opportunities for us to address a broader range of markets and applications while also allowing us to capture more content per electronic system.
Our new CV3 AI central domain controller family of SoCs is specifically architected for automated driving applications. In addition to offering our existing advanced camera perception processing, CV3 adds sensor fusion and planning layers that enable a broader set of fully-automated devices.
In November 2021, we acquired Oculii Corp., a developer of high definition radar technology. Oculii’s adaptive AI software algorithms are designed to enable radar perception using current production radar chips to achieve significantly higher resolution, longer range and greater accuracy. Oculii’s software can be deployed on our existing CVflow SoCs, operating in conjunction with leading radar RF solutions to significantly increase safety and reliability. We recently introduced a centralized radar architecture that synergistically leverages Oculii’s adaptive AI software algorithms together with our CV3 domain controller family, resulting in improved perception, lower power consumption and reduced bills-of-material for mobility applications compared to the current generation of radar systems utilized in the market today.
As described below, Ambarella’s products are now used in a wide variety of human viewing and computer vision applications, including a variety of automotive camera systems, video security cameras, mobile and fixed robots, industrial applications, and consumer devices, such as action, drone and 360° cameras. For our fiscal years ended January 31, 2023, 2022 and 2021, we recorded revenue of $337.6 million, $331.9 million and $223.0 million, respectively. For the fiscal years ended January 31, 2023, 2022 and 2021, we incurred net losses of $65.4 million, $26.4 million and $59.8 million, respectively. We have generated cash from operations in each fiscal year starting from 2009.
Industry Background and Target Markets
 Computer vision functionality has historically been executed with graphics processing units (GPU), field programmable gate-arrays (FPGA) or general purpose microprocessors (CPU) in servers or datacenters. This approach requires large amounts of data to be transported from an end-point electronic system or device into the network infrastructure, where the data may be stored, processed, and then sent back to the end point, creating added delay, power consumption and incremental expense from data communications, server processing and storage. In some applications, unacceptable levels of latency are introduced by the transportation of this data, minimizing or, in some cases, eliminating the utility of the product. In addition, this approach often requires personal information to be transmitted from the end-point device to the network infrastructure, potentially raising privacy and security concerns.
 



We believe the CV end-point market, sometimes referred to as the system’s edge, requires a fundamentally different SoC architecture versus the GPU, FPGA and CPU approach commonly used in the datacenter. Our CV SoCs are optimized for the requirements of the end-point market to provide highly accurate results, significant processing power, small form factor and minimal latency while consuming very low amounts of power and simultaneously delivering both human viewing and computer vision functionality, often while supporting multiple cameras and multiple AI applications with a single SoC incorporated in an end-point device. In addition, privacy and security can be enhanced, as critical personal information may not need to enter the network infrastructure.
Our first CV SoC was introduced in 2018 and CV3 is our third generation computer vision chip in our SoC family. Our development efforts are now focused on SoCs that provide both human viewing and computer vision functionality. With the acquisition of Oculii, we also now complement our advanced camera perception capabilities with advanced radar perception to enable higher levels of autonomy.
We are focusing on the automotive and Internet-of-Things (IoT) end markets:
•Automotive Applications. Cameras and other sensors, as well as high performance computing processors, are utilized for a variety of applications in the automotive market and our products are designed into both original equipment manufacturer (OEM) and aftermarket applications. We address the following automotive market applications:
 ▪Automotive Video Recorders (also known as data loggers). These video cameras are pre-installed in vehicles or mounted (aftermarket) to record events for reconciliation, such as for insurance and liability, driver scoring or training, and security purposes. We offer solutions for both OEM and aftermarket drive recording devices, some of which include advanced driver assistance systems (ADAS) features.
 ▪Electronic Mirrors. One or more cameras, in conjunction with an electronic display, are used to augment, or in some cases replace, reflective glass rear view and/or side view mirrors to provide a wider and unobstructed field of view. Smart electronic mirrors that incorporate our CV SoCs may also help with detecting objects in blind spots, overtaking vehicles and alerting for vulnerable road users, such as pedestrians and bicycles.
 ▪Front Advanced Driver Assistance System (ADAS) Cameras. These front-facing cameras are often positioned behind the rearview mirror, enabling functions such as automatic emergency braking, lane departure warning, forward collision warning, intelligent headlight control, and speed assistance functions, many of which are required by an increasing number of regional New Car Assessment Programs, or NCAP. The most advanced front ADAS cameras generally require ultra high-definition (UHD) resolution and advanced CV processing, which can be critical for long-distance object detection with a wide field-of-view, and extremely low power due to their inherently small form factor.


▪Cabin Monitoring System (CMS) and Driver Monitoring System (DMS) Cameras. These interior mounted cameras track drivers and passengers to help prevent accidents by alerting a drowsy or distracted driver and assisting with the deployment of safety features, such as airbags. These interior cameras may also be utilized by service providers, in particular with autonomous vehicles, to create new business opportunities in which in-cabin information, collected through cameras, may be monetized. Our solutions process our customers’ interior-sensing algorithms at high speeds and with low power consumption, and are effective even at night via onboard RGB-infrared processing. Our DMS solutions can be integrated with supplementary camera applications, including electronic mirror, front ADAS, and high-resolution driver recording.
 ▪Central domain controllers for L2+ to L4 Autonomous Vehicles. We continue to advance our research in critical areas of autonomous vehicle development, such as vehicle detection, obstacle detection, pedestrian detection, lane detection, traffic sign recognition, stereovision processing, and sensor fusion and planning, enabling us to design strong platforms for applications ranging from Level2+ autopilot to full autonomy. The CV3 family enables centralized, single-chip processing for multi-sensor perception, including high-resolution vision, radar, ultrasonic and lidar, as well as deep fusion for multiple sensor modalities and autonomous vehicle path planning. The central domain controller in autonomous vehicles is connected to the camera, radar and other sensor suites. Using neural network and traditional computer vision processing, the domain controller fuses the sensor data and perceives the vehicle’s surroundings. Based on this multi-sensor surround perception, the domain controller estimates a safe driving path for the vehicle. In addition, the domain controller can simultaneously process in-cabin sensing applications, including driver and occupant monitoring. 
 •Security Cameras. We are a leader in enterprise and home security camera markets, with solutions that deliver exceptional computer vision performance, industry-leading compression efficiency, low power consumption, and outstanding image quality, including high dynamic range (HDR), low-light processing and fisheye lens dewarping. Our CV products enable higher levels of automation than our vision processors through advanced algorithms, such as object detection, classification and tracking, license plate recognition and facial recognition. We address the following security camera applications:
 ▪Enterprise and Public Class Security. These cameras are used for video monitoring and security surveillance in enterprise and public infrastructure applications. Our solutions enable the streaming of multiple video streams to enable remote monitoring at multiple locations. Embedded computer vision technology supports advanced analytics at the system’s edge, including people counting and tracking, facial recognition and retail behavior analysis. 
 ▪Home Security. Home security cameras are designed for home or small business use and may be connected to cloud services and applications via home networks using WiFi. These cameras may require very low bitrate operation to support high-definition (HD) resolution over limited bandwidth connections, while their small form factors or battery powered design may require very low power operation. Form factors include smart video door-bells and video-enabled lights. Embedded computer vision technology supports advanced functions, including intruder and pet detection, face recognition and package monitoring. 
 •Emerging Robotic and Industrial Applications. Our solutions can add intelligence to a range of partially or fully robotic applications, including access control, industrial/factory automation, sensing cameras, and a variety of industrial and home robotic applications. Our advanced CV SoCs handle an array of complex algorithms, from low-level perception functions and neural networks to higher-level autonomous software stacks, while our video processing pipeline enables operation in challenging lighting conditions such as high-contrast scenes and extremely low-light environments, all with low power consumption. We address the following industrial and robotic market applications:
 ▪Identification/Authentication Cameras. Our video-based sensing solutions enable contactless access control for home, enterprise and public applications. Our CV SoCs are engineered to quickly extract input from the physical environment, fuse data from multiple sensors, analyze the incoming data and deliver the appropriate feedback, with low-latency and low-power responsiveness. Applications include enterprise access control panels, electronic locks and contactless mobile payment terminals. 
 ▪Robotic Products. Our products and technology are well suited for a variety of smart home and enterprise robotic applications. With stereovision capabilities and convolutional neural network (CNN)-based object classification, our solutions are also suited for a variety of industrial machine vision systems, mobile robots for delivery or factory/warehouse applications, aerial drones, robotic vacuum cleaners, and other emerging robotic applications.
 ▪Sensing Cameras. Our CV SoCs enable sensing cameras that analyze video using AI-based algorithms running in the camera to provide remote users with updates, warnings or business data based on the analysis. Since no video, audio or image data needs to leave the camera, privacy can be prioritized. Applications for sensing cameras include elderly monitoring, building occupancy monitoring and retail store business analytics.


•Other IoT Applications. Cameras for the home, public spaces and consumer leisure applications that provide HD video quality increasingly include embedded connectivity to share and display video. Our low power, high-resolution and connected solutions can be found in a variety of cameras, including wearable body cameras, sports action cameras, social media cameras, drones for capturing aerial video or photographs, video conferencing and virtual reality applications.
 
Our Competitive Strengths
Our platform technology solutions provide performance attributes that satisfy the stringent demands of the camera market, enable integration of HD video and image capture capabilities in portable devices, and provide computer vision capabilities that address the evolving needs of the automotive and IoT markets. We believe that our leadership is the result of our competitive strengths, including:
 •Proprietary AI, Radar and Computer Vision Architecture. Our proprietary AI and computer vision processing architecture, known as CVflow, uses a flexible hardware engine programmed with a high level algorithm description to achieve increased performance while minimizing die size and power consumption. The CVflow architecture specifies data flow connections between a set of optimized AI and computer vision operators, such as the convolution and matrix multiply functions that are specifically optimized for deep learning algorithms. The CVflow architecture supports a variety of AI, radar and computer vision algorithms, including object detection, classification and tracking, semantic and instance segmentation, image processing, and stereo object detection. CVflow also allows customers to differentiate their products by porting their own algorithms and neural networks to our SoCs. 
 •Deep Sensor Fusion. Ambarella provides AI perception processing for cameras, and with the acquisition of Oculii we provide software that enables efficient HD 4D radar perception. Our CV3 SoC family implements centralized camera and radar perception processing on the same SoC, allowing data from all camera and radar sensors in the sensor suite to be fused at a deeper data level, which we believe will facilitate improved levels of perception accuracy.
 •High-Performance, Low Power, AI, Video and Image Algorithm Expertise. Our extensive algorithm expertise, which facilitates efficient AI, video and image compression, enables our solutions to achieve low power consumption without compromising performance. Our solutions provide Full HD and UHD video up to 32-megapixel resolution and 60 frames per second. Our solutions achieve high storage and transmission efficiencies through innovative and complex video and image compression algorithms that significantly reduce the output bitrate. This smaller storage footprint directly benefits the performance of our solutions in several ways, including lower memory storage requirements and reduced bandwidth needs for transmission, which both facilitate sharing content between devices. These benefits are particularly important in transcoding, the digital-to-digital conversion of one encoding format to another, and video cloud applications. Our solutions can deliver clear images in low light conditions because of our advanced noise reduction, including 3D motion compensated temporal filtering (MCTF) and multiple exposure processing. Additionally, our HDR processing capabilities handle scenes with large dynamic range between the lightest and darkest areas to reveal details that would otherwise be lost in shadow or highlight areas. Our advanced de-warping capability enables cameras to use wide angle lenses, making it ideal for a variety of security camera applications, as well as 3D electronic image stabilization and surround view for automotive applications.
 •Highly Integrated SoC Solutions Based on a Scalable Platform. Our product families leverage a flexible and highly-scalable platform including our core high-performance AI and video processing architecture combined with an extensive set of integrated peripherals. Our flexible and highly-scalable platform enables our customers to address multiple applications and markets with reduced design cycles and costs. Our software compatible portfolio of products, with a broad range of performance and price points, allows our customers to develop a range of end products from a common software base. 
 •Comprehensive and Flexible Software. Our years of investment in developing and optimizing our comprehensive and flexible software serve as the foundation of our high-performance video application solutions. Key components of our software include highly customized middleware that integrates many unique features for efficient scheduling and other system-level functions, and firmware that is optimized to reduce power requirements and improve performance. In addition, we provide our customers full-function software development kits with a suite of application programming interfaces or APIs, which allow customers to rapidly integrate our solution, adjust product specifications and provide additional functionality to their systems, thereby enabling them to differentiate their product offerings and reduce time to market. We also provide extensive software tools to map algorithms from commonly-used AI frameworks such as PyTorch or TensorFlow into our proprietary CVflow architecture. Our software development kits (SDKs) contain reference code for specific features that customers can quickly deploy. 
Products
We have a wide range of products in our portfolio, including products that have commercially shipped, products for which we have shipped engineering samples and products that are under development. We typically introduce two to three new silicon products per year which, when combined with our flexible software development kits, allow us to offer product families addressing the specific needs of a wide range of end markets. In addition to enabling small device size and low power consumption, our SoC solutions make possible differentiated functionalities, such as computer vision functionality, simultaneous video and image capture, multiple-stream video capture, image stabilization and wireless connectivity.
Central Domain Controller. Our new CV3-AD685, the first production version of the CV3 family of automotive AI domain controllers, targets L2+ to L4 autonomous vehicles. Its next-generation CVflow® AI engine includes neural network processing that is 20x faster than the previous generation of CV2 SoCs, along with additional general vector processing capabilities to provide the overall performance required for full autonomous driving (AD) stack processing, including computer vision, HD radar, deep fusion and planning. It also integrates advanced image processing, a dense stereo and optical flow engine, Arm® Cortex® A78AE and R52 CPUs, an automotive GPU for visualizations, and a hardware security module (HSM). The CV3-AD685 is an “algorithm first” architecture that provides support for the entire AD software stack.
CVflow SoCs. Our AI architecture, incorporated into our CV family of SoCs, extracts and processes data from video streams, enabling our customers to develop intelligent camera systems. These SoCs combine advanced image processing, high-resolution video encoding and CVflow AI processing in a single, low-power design to enable a new class of smart edge devices for applications including smart home security, retail monitoring, consumer robotics, and occupancy monitoring. Some of our CVflow SoCs are manufactured to satisfy the functional safety requirements of the automotive market.
 
Vision Processor SoCs. Our video and image processing SoCs, based on our proprietary architecture, integrate an advanced image sensor pipeline (ISP), H.264 and/or H.265 encoders, and a powerful ARM CPU for advanced analytics, flight control, WiFi streaming, and other user applications. Our unique architecture and advanced process node technology lower power consumption while maintaining high performance for security camera and consumer applications such as connected drones, sports cameras, and 360º (VR) cameras.

High Definition Radar. Through our acquisition of Oculii, we offer adaptive AI software algorithms designed to enable radar perception using current production radar chips to achieve significantly higher resolution, longer range and greater accuracy. These improvements eliminate the need for specialized high-resolution radar chips, which have significantly higher power consumption and cost than conventional radar solutions. Oculii’s software can be deployed on Ambarella’s existing CVflow SoCs, operating in conjunction with leading radar RF solutions to increase safety and reliability. In addition, we recently introduced a centralized radar architecture that leverages Oculii’s adaptive AI software algorithms together with our CV3 processor family to enable both central processing of raw radar data and deep, low-level fusion with other sensor inputs, including cameras, lidar and ultrasonics.
 Serializer/Deserializers. Our B6 and B8 SerDes (Serializer/Deserializer) products are mixed-signal (analog and digital) semiconductors used to transport data short distances (up to 10 meters) from a CMOS image sensor, often in a remote camera location, to our video and CV SoCs. The SerDes chips are used to add additional camera(s) to an automotive application, as well as used as a bridge chip for other automotive applications, such as a MIPI combiner, splitter or display driver. Our SerDes chips are also used in security applications such as ATMs that can use a single B8 chip for connecting multiple remote cameras to a single video processor SoC.
 Software Modules. In the future, we may separately license proprietary software modules that can be used in conjunction with a customer’s internally developed software and/or with third-party software. Features that may be licensed include functionality for a variety of automotive applications, including dataloggers, ADAS and autonomous driving systems, eMirrors and in-cabin applications. Additionally, our neural-network image signal processing (NN-ISP) software module improves low light imaging in security camera applications.


The chart below describes our current product lines:




Technology

Our semiconductor processing solutions enable artificial intelligence and computer vision processing, HD, UHD and 8K UHD (up to 7680 x 4320p60) video and image processing, and video compression, sharing and display while offering exceptional power, size, and performance characteristics.
Key differentiators of our technology include:
•flexible and scalable CVflow processors for deep learning, HD radar processing and other CV algorithms that cover a broad range of consumer, professional and automotive requirements with power and die size efficiency; 
 •stereo/optical flow processing engines for robust CV processing with high performance and power efficiency;
 •scalable image processing and video compression engines that cover consumer, professional and automotive requirements from Full HD to 8K video performance levels as well as multiple image sensors simultaneously to support multiple viewpoints, including surround view and virtual reality applications; 
 •algorithms for image processing including deep learning augmented processing for challenging low light and high dynamic range conditions for robust CV and human viewing with high power efficiency. 
 •algorithms and software for scalable and robust HD 4D radar processing using sparse antenna arrays using machine learning and adaptive transmit waveforms for lower cost and better power efficiency;
 •deep learning algorithms and software for multi class 2D/3D object detection and segmentation, including vehicles, pedestrians, cycles, road markings, traffic signs and traffic lights optimized for our CV2 and CV3 SoC families;
 •algorithms and software for stereo obstacle detection to provide robust safety in the event of obstacles that are not in the training data; 
 •autonomous driving stack modules optimized for our CV3 SoC family, including fusion for multiple cameras and sensor modalities, mapping and localization algorithms and planning;
 •algorithms to compress video signals with high compression and power efficiency at multiple operating points; 
 •software development kit comprised of application programming interfaces, or APIs, to facilitate integration into customers’ products; and tools for porting and optimizing customer deep neural networks, or DNNs, developed in industry standard training frameworks; 
 •low-power architecture with minimal system memory footprint; and
 •programmable architecture that balances flexibility, quality, power and die size with powerful CPUs and optimized hardware acceleration to support advanced processing functions.


Our technology platform is based on a high-performance, low-power architecture supported by a high level of system integration. The building blocks of our platform are illustrated below:


Our technology platform enables the capture of high-resolution still images and UHD video while simultaneously performing CV processing and encoding for high-quality storage and lower resolution real time streaming.

CVflow
 
Our proprietary AI computer vision processing architecture, known as CVflow®, uses a flexible hardware engine programmed with a data flow graph algorithm description to achieve increased performance while minimizing die size and power consumption. This description allows the hardware to maximize use of its resources by exploiting all available parallelism without software intervention. The CVflow architecture specifies data flow connections between a set of optimized AI and computer vision operators, such as the convolution and matrix multiply functions that are used for deep learning algorithms. The CVflow architecture also supports a variety of other algorithms, including radar processing, stereo obstacle detection and sensor fusion. Our platform allows customers to differentiate their products by porting and optimizing their own algorithms and neural networks to our CVflow-based chips using industry-standard training tools and APIs.
 
Computer Vision and Radar Technology
 
Computer vision is a core technology that complements our proprietary image processing and video compression technology. We have developed efficient deep learning algorithms for object detection and segmentation leveraging our deep understanding of the CVflow processor. A significant feature of our third generation CVflow SoCs is support for HD stereo and HD radar based depth and velocity sensing. We believe HD stereo and HD radar are complementary sensor modalities that provide robust depth information after fusion. This depth information provides an important augmentation to monocular computer vision processing, resulting in an extra margin of safety for autonomous driving and other applications. Monocular processing depends on training to detect obstacles, and may not detect obstacles that are not represented in the training set. Stereo cameras and radar detect obstacles without relying on training for specific obstacle categories because the depth information is used to directly construct a three-dimensional model of the camera’s surroundings, including any obstacles. This allows more robust decisions to be made in applications such as autonomous driving.
 

Compatible Family of SoC Solutions

Our current SoC designs integrate our fully-programmable and highly-efficient CVflow architecture, UHD image processing and video compression, applications processing and system functions onto a single chip, delivering exceptional performance, quality and power efficiency with differentiated features. Our multi-core DSP architecture is highly scalable and balances software programmability with hardware-accelerated performance to achieve extremely low power consumption and maximized camera battery life. We have used this scalability to develop an extensive family of software compatible SoCs with a wide range of performance and price points (CV28, CV25, CV22, CV2, CV2FS, CV5, CV3 AD685, and CV-3 High Dev). This scalable, programmable architecture provides our customers with the flexibility they need to quickly develop a wide range of differentiated products. Additionally, our SoCs integrate mixed signal (analog/digital) functionality and high speed interfaces required for interfacing to advanced high-speed CMOS sensors and industry standard interfaces such as PCI-E, USB 3.2 and HDMI 2.0. Our next generation CV3 family extends our CVflow architecture to cover L2+/L3/L4 autonomous driving and other high performance safety critical applications. The CV3 family will cover multiple performance and price points with a software compatible SDK.
 
Software Development Kits

We provide to our customers fully-functional software development kits with a suite of APIs which allow customers to rapidly integrate our solution, adjust product specifications and provide additional functionality to their systems, thereby enabling them to differentiate their product offerings and reduce time to market. We have software development kits for all of our core markets.

We also provide a toolkit to accelerate the development of computer vision algorithms onto our hardware. We provide tools to map and optimize algorithms developed in commonly used computer vision frameworks such as PyTorch or TensorFlow into our proprietary CVflow architecture. We also provide a framework for development of higher-level computer vision tasks. This enables our customers to write complex computer vision algorithms with multiple tasks running in parallel on multiple processing engines, as would be required in applications such as autonomous driving.

Software Modules

We are developing optimized software modules to give customers the option to leverage our expertise and reduce development time and expense. These modules include HD radar processing for standalone and central radar processing, DL based low light and HDR image processing, monocular and stereo camera perception, and autonomous driving stack modules optimized for the CV3 family, including fusion for multiple cameras and sensor modalities, mapping and localization algorithms and planning.
 
AmbaClear

Our proprietary image signal processing architecture, known as AmbaClear, incorporates advanced algorithms to convert raw sensor data to UHD video and/or still images. Image processing algorithms include sensor, lens and color correction, HDR tone mapping, color processing and de-mosaicing to reconstruct a full color image from incomplete color samples and specialized color filters, noise filtering, detail enhancement and image format conversion. For example, raw sensor data can be captured at up to 32-megapixel (8K) resolution at 60 frames per second. This image processing reduces noise in the sensor data and improves color, contrast and sharpness resulting in improved computer vision performance, enhanced human viewing and enhanced storage and transmission efficiencies. Our WDR and HDR processing capabilities handle greater dynamic range between the lightest and darkest areas of an image, permitting video images to reveal details that would otherwise be lost against a bright background. We have developed efficient scalable deep learning algorithms for advanced low light processing and HDR tone mapping that augment our image processing hardware. These algorithms provide significant image quality improvements over our standard image processing while running in real time at HD and higher resolutions. Our advanced de-warping capability enables cameras to use wide angle lenses to capture images from a wide area, making it ideal for a variety of IP security camera and surround view applications. Our RGB- infrared fusion capability allows a single sensor to produce simultaneous RGB and infrared images for sensing and improved low light performance.
 
AmbaCast

Our proprietary UHD video compression architecture, known as AmbaCast, incorporates advanced algorithms for motion estimation, motion-compensated 3D temporal filtering, mode decision and AI based rate control. Successful implementation of these computationally intensive steps has helped us maximize compression efficiency. We support H.264 and H.265 video compression standard with our H.265 providing up to 2x better compression efficiency compared to our H.264 video compression technology.
 

Design Methodology

 The success of our technology platform stems from our algorithm driven design methodology. We do extensive algorithm studies in deep learning AI, image processing and compression including our internally developed and public external algorithms. We use these studies to develop high power and die area efficient processing engines compared with general purpose processors like CPUs and GPUs. We also include a high degree of programmability to provide flexibility in supporting new algorithms that we and our customers develop. We test and verify our algorithms on our proprietary architectural model prior to implementing our processor engines in hardware. Our advanced verification methodology validates our approach through simultaneous modeling of architecture, algorithms, and the hardware itself. This redundant approach enables us to identify and remediate any weaknesses early in the development cycle, providing a solid foundation on which we build our hardware implementation, and enhances our ability to achieve first-pass silicon success. We possess extensive expertise in AI deep learning, video and imaging algorithms, as well as deep sub-micron digital and mixed-signal design experience.
Customers
 We sell our solutions to leading original design manufacturers, or ODMs, and original equipment manufacturers, or OEMs, globally. In the automotive OEM market, we may sell our solutions to Tier-1 suppliers that develop and sell devices incorporating our solutions to automotive OEMs. We refer to ODMs and Tier-1 suppliers as our customers and OEMs as our end customers, except as otherwise indicated or as the context otherwise requires.
Sales to customers in Asia accounted for approximately 82%, 88%, and 88% of our total revenue in the fiscal years ended January 31, 2023, 2022, and 2021, respectively. As many of our OEM end customers or their ODM manufacturers are located in Asia, we anticipate that a majority of our revenue will continue to come from sales to customers in that region. Although a large percentage of our sales are made to customers in Asia, we believe that a significant number of the products designed by these customers and incorporating our SoCs are then sold to consumers globally. To date, all of our sales have been denominated in U.S. dollars.
We work closely with our end customer OEMs and ODMs throughout their product design cycles that often last nine to eighteen months for many of our target markets, although new products may have longer design cycles, particularly those implementing advanced AI features. Product design cycles for certain portions of the automotive market generally last longer than eighteen months, particularly for products containing user safety features. As a result, we are able to develop long-term relationships with our customers as our technology becomes embedded in their products. Consequently, we believe we are well positioned to not only be designed into our customers’ current products, but also to continue to develop next-generation HD video and image processing solutions for their future products.
The product life cycles in many of our target markets typically range from twelve to 24 months. We expect that product lifecycles in the automotive OEM and the industrial and robotics markets will typically be longer than 24 months, as new product introductions occur less frequently. For many of our solutions, early engagement with our customers’ technical staff is necessary for success.
In fiscal year 2023, the customers representing 10% or more of revenue were Wintech Microelectronics Co., Ltd., or WT, our Asia-based distributor, and Chicony Electronics Co., Ltd., or Chicony, a direct ODM customer that manufactures products for multiple end-customers, which accounted for approximately 57% and 12% of total revenue, respectively. We currently rely, and expect to continue to rely, on a limited number of customers for a significant portion of our revenue.
Sales and Marketing
We sell our solutions worldwide using our direct sales force and our distributors. We have direct sales personnel covering the United States, Asia and Europe, and we operate sales offices in Santa Clara, California and Hong Kong, and business development offices in China, Germany, Japan, South Korea, and Taiwan. In addition, in each of these locations we employ a staff of field applications engineers to provide direct engineering support locally to our customers.

Our sales cycles typically require a significant investment of time and a substantial expenditure of resources before we can realize revenue from the sale of our solutions, if any. Our typical sales cycle consists of a multi-month sales and development process involving our customers’ system designers and management and our sales personnel and software engineers. If successful, this process culminates in a customer’s decision to use our solutions in its system, which we refer to as a design win. Our sales efforts are typically directed to the OEM of the product that will incorporate our computer vision and video and image processing solution, but the eventual design and incorporation of our SoC into the product may be handled by an ODM or Tier-1 supplier on behalf of the OEM. Volume production may begin within nine to 18 months after a design win, depending on the complexity of our customer’s product and other factors upon which we may have little or no influence. Once our solutions have been incorporated into a customer’s design, they are likely to be used for the life cycle of the customer’s product. Conversely, a design loss to a competitor will likely preclude any opportunity for future revenue from such customer’s product.
Our sales are generally made pursuant to purchase orders received approximately four to 30 weeks prior to the scheduled product delivery date, depending upon agreed terms with our customers and the current manufacturing lead time at the time the purchase order is received. These purchase orders may be cancelled without charge upon notification within an agreed period of time in advance of the delivery date. Our standard warranty provides that our SoCs containing defects in materials, workmanship or performance may be returned for a refund of the purchase price or for replacement, at our discretion. We may agree to different warranty terms with specific customers from time to time.
Our sales are primarily made through standard purchase orders for delivery of products. Our manufacturing production is based on estimates and advance non-binding commitments from customers as to future purchases. We follow industry practice that allows customers to cancel, change or defer orders with limited advance notice prior to shipment. Given this practice, we do not believe that backlog is a reliable indicator of future revenue levels.
Manufacturing
We employ a fabless business model and use third-party foundries and assembly and test contractors to manufacture, assemble and test our solutions. This outsourced manufacturing approach allows us to focus our resources on the design, sales and marketing of our solutions and avoid the cost associated with owning and operating our own manufacturing facility. Our engineers work closely with foundries and other contractors to increase yields, lower manufacturing costs and improve quality. In addition, we believe outsourcing many of our manufacturing and assembly activities provides us the flexibility needed to respond to new market opportunities, simplifies our operations and significantly reduces our capital requirements. We do not have a guaranteed level of production capacity from any of our suppliers’ facilities to produce our solutions. We carefully qualify each of our suppliers and their subcontractors and processes in order to meet the extremely high-quality and reliability standards required of our solutions.
Wafer Fabrication
We have a history of using several process nodes from 130 nm through 5 nm. We aim to use the most advanced manufacturing process technology appropriate for our products that is available from our third-party foundries. As a result, we periodically evaluate the benefits of migrating our solutions to smaller geometry process technologies in order to improve performance and efficiency. We believe this strategy will help us remain competitive. While we currently manufacture the majority of our solutions in the 28 nm, 14 nm and 10 nm process nodes, our most recent products are manufactured in the 5 nm process node. Currently, the substantial majority of our SoCs are supplied by Samsung in facilities located in Austin, Texas and South Korea, from whom we have the option to purchase both fully-assembled and tested products as well as tested die in wafer form for assembly. We also have small volumes of some products supplied by GlobalFoundries Inc. Our foundry vendors are ISO 9001 certified.
Assembly and Testing
Samsung subcontracts the assembly and initial testing of the assembled chips it supplies to us to Signetics Corporation and STATS ChipPAC Ltd. In the case of purchases of tested die from Samsung, we contract the assembly to Advanced Semiconductor Engineering, Inc., or ASE. We contract the assembly of products supplied by Global Foundries Inc. to ASE. Final testing of our products is handled primarily by Sigurd Corporation or King Yuan Electronics Co., Ltd. under the supervision of our engineers. All test software and related processes for our products are developed by our engineers. We continually monitor the results of testing at all of our test contractors to ensure that our testing procedures are properly implemented.
As part of our total quality assurance program, our quality management system has been certified to ISO 9001:2015 standards. Our assembly and testing vendors are also ISO 9001 certified.

Due to the scheduling requirements of our foundry, assembly and test contractors, we generally provide our contractors with our production forecasts and place firm orders for products with our suppliers up to 36 weeks prior to the anticipated delivery date, or potentially longer during times of acute capacity shortages, usually without a purchase order from our own customers.
 Research and Development
We believe our technology is a competitive advantage and we engage in substantial research and development efforts to develop new products and integrate AI computer vision capabilities into our HD and UHD video processing solutions. We believe that our continued success depends on our ability to both introduce improved versions of our existing solutions and to develop new solutions for the markets that we serve. As of January 31, 2023, approximately 74% of our employees are engaged in research and development. Our research and development team is comprised of both semiconductor and software designers. Our semiconductor design team has extensive experience in large-scale semiconductor design, including architecture description, logic and circuit design, implementation and verification. Our software design team has extensive experience in development and verification of software for the HD video market. Because the integration of hardware and software is a key competitive advantage of our solutions, our hardware and software design teams work closely together throughout the product development process. The experience of our hardware and software design teams enables us to effectively assess tradeoffs and advantages when determining which features and capabilities of our solutions should be implemented in hardware and in software.
We have assembled a core team of experienced engineers and systems designers in four research and development design centers located in the United States, China, Italy, and Taiwan.
Competition
The global semiconductor market in general, and the AI and video and image processing markets in particular, are highly competitive. We expect competition to increase and intensify as more and larger semiconductor companies enter our markets and as we penetrate new markets, such as the automotive OEM market. Increased competition could result in price pressure, reduced profitability and loss of market share, any of which could materially and adversely affect our business, revenue and operating results.
Our competitors range from large, international companies offering a wide range of semiconductor products to smaller companies specializing in narrow markets. In the IoT market, our primary competitors include AMLogic Inc., Fuzhou Rockchip Electronics Co., Ltd., HiSilicon Technologies Co., Ltd., or HiSilicon, which is owned by Huawei Technologies Co., Ingenic Semiconductor Co., Ltd., Novatek Microelectronics Corp., or Novatek, NVIDIA Corporation, or NVIDIA, OmniVision Technologies, Inc., Qualcomm Incorporated, or Qualcomm, Sigmastar Technology Ltd., and Socionext Inc. In the automotive camera market, we compete against Allwinner Technology Co., Ltd., Horizon Robotics Inc., iCatch Technology, Inc., Mobileye, a subsidiary of Intel Corporation, Novatek, NVIDIA, NXP Semiconductors N.V., Qualcomm, Renesas Electronics Corporation, and Texas Instruments. Certain of our customers and suppliers also have divisions that produce products that compete with ours.
 Our ability to compete successfully depends on elements both within and outside of our control, including industry and general economic trends. Many of our competitors are substantially larger, have greater financial, technical, marketing, distribution, customer support and other resources, are more established than we are, and have significantly better brand recognition and broader product offerings which may enable them to develop and enable new technology into product solutions better or faster than us and to better withstand adverse economic or market conditions in the future.
Our ability to compete successfully in the rapidly evolving camera markets depends on several factors, including:
•the design and manufacturing of new solutions, including software, that anticipate the video processing and integration needs of our customers’ next-generation products and applications; 
 •performance of our computer vision solutions, as measured by convolutional neural network performance, video and still picture image quality, resolution and frame processing rates; 
 •power consumption efficiency of our solutions; 
 •the ease of implementation of our products by customers; 
 •the strength of our customer relationships; 
 •the selection of the foundry process technology and architecture tradeoffs to meet customers’ product requirements in a timely manner; 


•reputation and reliability; 
 •customer support; and 
 •the cost of the total solution. 
 We believe we compete favorably with respect to these factors, particularly because our solutions typically provide high-performance and low power consumption video, CNN performance, efficient integration of our advanced algorithms, exceptional storage and transmission efficiencies at lower power, highly-integrated SoC solutions based on a scalable platform, and comprehensive and flexible software. We cannot ensure, however, that our solutions will continue to compete favorably or that we will be successful in the face of increasing competition from new products introduced by existing or new competitors.
Intellectual Property
We rely on a combination of intellectual property rights, including patents, trade secrets, copyrights and trademarks, and contractual protections, to protect our core technology and intellectual property. As of January 31, 2023, we had 300 issued patents in the United States, 109 of which were continuation or divisional patents, 10 issued patents in Europe, 7 issued patents in China, 7 issued patents in Japan and 86 pending patent applications in the United States. The issued patents in the United States expire beginning in 2024 through 2042. Our issued patents and pending patent applications primarily relate to image and video processing and HD video compression, AI processing, system level camera, and radar perception applications spanning multiple market segments.
We may not receive competitive advantages from any rights granted under our patents, and our patent applications may not result in the issuance of any new patents. In addition, any patent we hold may be opposed, contested, circumvented, designed around by a third party or found to be unenforceable or invalidated. Others may develop technologies that are similar or superior to our proprietary technologies, duplicate our proprietary technologies or design around patents owned or licensed by us.
In addition to our own intellectual property, we also use third-party licenses for certain technologies embedded in our SoC solutions. These are typically non-exclusive contracts provided under royalty-accruing or paid-up licenses. These licenses are generally perpetual or automatically renewed for so long as we continue to pay any maintenance fees that may be due. To date, maintenance fees have not constituted a significant portion of our capital expenditures. While we do not believe our business is dependent to any significant degree on any individual third-party license, we expect to continue to use and may license additional third-party technology for our solutions.
We generally control access to and use of our confidential information through employing internal and external controls, including contractual protections with employees, contractors and customers. We rely in part on U.S. and international copyright laws to protect our mask work. All employees and consultants are required to execute confidentiality agreements in connection with their employment and consulting relationships with us. We also require them to agree to disclose and assign to us all inventions conceived or made in connection with the employment or consulting relationship.
Despite our efforts to protect our intellectual property, unauthorized parties may still copy or otherwise obtain and use our software, technology or other information that we regard as proprietary intellectual property. In addition, we continue to operate internationally, and effective patent, copyright, trademark and trade secret protection may not be available or may be limited in foreign countries.
Seasonality
Our business has tended to be seasonal with higher revenue in our second and third fiscal quarters as our customers typically increase their production to meet holiday shopping season or year-end demand for their products. We also may experience seasonally lower demand in our first and fourth fiscal quarters due in part to the Asia-based portion of the security camera market as a result of industry seasonality and the impact of ODM and OEM factory closures associated with the Chinese New Year holiday. These seasonal fluctuations may diminish if our revenue diversifies and becomes less dependent on sales of our customers’ consumer products.
Governmental Regulation
 Our business and operations around the world are subject to government regulation at the national, state or local level addressing, among other matters, applicable environmental laws, health and safety laws and regulations, laws relating to export controls and economic sanctions, and the rules of industrial standards bodies such as the International Standards Organization and governmental agencies such as the Federal Trade Commission.



We believe that our properties and operations comply in all material respects with applicable laws protecting the environment and worker health and safety. As a fabless semiconductor company, we do not manufacture our own products but do maintain laboratory space at certain of our facilities to facilitate the development, evaluation and testing of our SoC products. These laboratories may maintain small quantities of hazardous materials. While we believe we are in material compliance with applicable law concerning the safeguarding of these materials and with respect to other matters relating to health, safety and the environment, the risk of liability relating to hazardous conditions or materials cannot be eliminated completely. To date, we have not incurred significant expenditures relating to environmental compliance at our facilities nor have we experienced any material issues relating to employee health and safety.

In addition to environmental and worker health and safety laws, our business is subject to various rules and regulations and executive orders relating to export controls and trade sanctions. Certain of our products are subject to the Export Administration Regulations (EAR), which are administered by the United States Department of Commerce’s Bureau of Industry and Security (BIS), and we may from time to time be required to obtain an export license before we can export certain products or technology to specified countries or customers. In addition, the EAR imposes broad controls on entities listed on sanctioned persons lists, including the BIS Entity List. If one of our customers is listed on the BIS Entity List or another U.S. government sanctioned persons’ list, then subject to certain exceptions, we will, as a general rule, be precluded from doing business with that customer. For example, certain of our Chinese customers, or their affiliated entities, have been added to the BIS Entity List in the last couple of years, which limits our ability to ship certain products to these customers. We cannot guarantee that export control restrictions or sanctions imposed in the future will not prevent, or materially limit, our ability to conduct business with certain customers or in certain countries. Any failure to comply with these laws could result in governmental enforcement actions, including substantial monetary penalties and denial of export privileges.
 Human Capital Resources
 Innovation has been the lifeblood of our company since our founding in 2004. We continually strive to develop leading-edge image and video, and now AI, processors using the most advanced semiconductor processes available to create high performance, power efficient SoCs. We depend on our people to sustain our competitive advantages.

As of January 31, 2023, we employed a total of 937 people, including 260 in the United States, 595 in Asia, primarily 355 in Taiwan and 223 in China, and 82 in Europe. Approximately 74% of our employees are engaged in research and development, 2% in operations, and 24% in sales, marketing and administration. As of January 31, 2023, females represented 29% of our independent directors, 21% of senior management, 16% of our technical roles, and 20% of our total workforce. Of our total employee workforce, 38% is represented by a work council in Taiwan. The work council group, which is common in Taiwan, is comprised of employees elected by the general employee base in that location. We consider our global employee relations to be good. Despite employees working in geographically disparate locations and differences in cultures, we strive to treat all employees as part of one team working together. Our Chief Executive Officer holds quarterly town hall style meetings with employees of all of our offices to keep employees apprised of company activities and objectives and to provide an opportunity for all employees to meet and ask questions. All employees receive training in the prevention of sexual harassment and abusive conduct in the workplace.
 
Our human capital resources objectives include attracting and retaining talented and experienced employees. We utilize multiple online search tools, specialized recruiting firms, employee referral programs and university hires to ensure a varied outreach approach for candidates. We are committed to ensuring the human rights of our worldwide workforce and treating all employees with dignity and respect. We offer a combination of competitive base salary, time-based equity incentives and bonus plans linked to financial and strategic performance that are designed to motivate and reward personnel with annual grants of stock-based and cash-based incentive compensation awards, plus other benefits, in order to increase stockholder value and the success of our company by motivating such individuals to perform to the best of their abilities and achieve both our short and long-term objectives. We offer competitive benefits tailored to local markets and laws and designed to support employee health, welfare and retirement; examples of such benefits include paid time off; 401(k), pension or other retirement plans; an employee stock purchase plan; basic and voluntary life, disability and supplemental insurance; medical, dental and vision insurance; health savings and flexible spending accounts; relocation assistance; and employee assistance programs. Approximately 81% of eligible U.S. employees participate in our 401(k) plan, and 89% of eligible employees participated in the most recent offering period of our employee stock purchase plan.
 
The average tenure of our employees is approximately 7.4 years and approximately 30% of our employees have been employed by us for more than 10 years. We believe our compensation and benefits packages, combined with our culture that promotes teamwork, innovation and hands-on experience from the first day of employment, contribute to low employee turnover and an above-average tenure. We monitor employee turnover rates by region and our company as a whole. Our worldwide voluntary employee turnover rate in fiscal year 2023 was approximately 7.4%.
 

Our primary focus during the COVID-19 pandemic has been protecting the health and safety of our employees and the communities in which we operate. In our locations that have experienced high rates of infection, employees have worked remotely to reduce spread of the virus.
Corporate Information
 Ambarella was founded and incorporated in the Cayman Islands in January 2004. Our registered address is PO Box 309GT, Ugland House, South Church Street, George Town, Grand Cayman, Cayman Islands. The address of our U.S. operating subsidiary is Ambarella Corporation, 3101 Jay Street, Santa Clara, California. The Securities and Exchange Commission, or SEC, maintains a website at www.sec.gov that contains reports, proxy, and information statements, and other information regarding registrants that file electronically. You may also obtain copies of our Forms 10-K, 10-Q, 8-K, and other filings with the SEC, and all amendments to these filings, free of charge, by visiting the Investor Relations page on our website (http://investor.ambarella.com) as soon as reasonably practicable following our filing of any of these reports with the SEC. Information on our website is not incorporated into this Annual Report on Form 10-K or our other securities filings and is not a part of such filings.
